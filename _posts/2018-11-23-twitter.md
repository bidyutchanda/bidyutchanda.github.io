---
layout: post
title: Tweet Sentiment Analyzer
subtitle: Sentimentally analyzing tweets and subsequent projection on Leaflet Map
show-avatar: false
bigimg: /img/twitter.png
share-img: /img/twitter.png
gh-repo: bidyutchanda/Tweet-based-Trends-plotting-using-Hashtags
gh-badge: [star, fork, follow]
tags: [python,twitter,sentiment analysis,textblob,folium,map]
---

## Story behind this project

Founded in 2006, Twitter is the walking and talking overview of what is going on in our world right now, since quite a few years. I can not make a list, if I want to even, of all the areas which Twitter hosts information upon; let us decide on, almost everything which a person can even think of and a lot (x3) more. And since when Machine Learning has started being a coffee table discussion for enthusiasts, a feature of ML me and another project contributor, [Debanik Banerjee](https://github.com/Debanik) could exploit was Sentimental Analysis over texts, obviously with the help of Python, a Twitter API to fetch tweet texts and some open source packages already created by developers (all of which will be mentioned below for reference).

## Project Details

You can find the code for this project at GitHub [here](https://github.com/bidyutchanda/Tweet-based-Trends-plotting-using-Hashtags) and can fork or star it from the buttons above. 

## Packages used  

All the packages used in this project are open-source and are available at PyPi.
* [TextBlob](https://textblob.readthedocs.io/en/dev/) - For sentimentally analysing the tweets.
* [Folium](https://github.com/python-visualization/folium) - For creating a Leaflet map from location parameters.
* [Tweepy](http://www.tweepy.org/) - An open source API for fetching twitter data.
* [Geopy](https://pypi.org/project/geopy/) - For geocoding the location name to latitude and longitude pairs.
* [Tweet-Preprocessor](https://pypi.org/project/tweet-preprocessor/) - For cleaning the tweets.

## Working of the script

The code opens with the _import_ statements to import all the packages which I have used for this.

```python
import folium
import tweepy
from textblob import TextBlob
import preprocessor as p
from geopy.geocoders import Nominatim
```

A Twitter developer account is necessary to integrate with Tweepy, for fetching the tweets. When you sign up for a developer account, four authentication values are provided to authenticate the API, while using inside the script. The values should be put like this as different variables inside the Python script.

```python
consumer_key = "<Your Consumer Key Goes Here>"
consumer_secret = "<Your Consumer Secret Token Goes Here>"
access_token = "<Your Access Token Goes Here>"
access_secret = "<Your Access Secret Token Goes Here>"
```

Tweepy now authenticates these values and retrieves the permission from Twitter to fetch live tweets via these lines. 

```python
auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_secret)
api = tweepy.API(auth,wait_on_rate_limit=True)
```

Two inputs are asked from the user. One is the hashtag (a String) against which the tweets are to be fetched and another is a limiting value (an integer), because we don't want the fetching process to go on forever. 

```python
hashtag = raw_input("Input the hashtag for which tweets are to be extracted: ")
limiting_value=int(raw_input("Input the number of live tweets that are to be extracted: "))
```






```









